{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis Assignment - Template\n",
    "\n",
    "**Course:** [Insert Course Name]  \n",
    "**Assignment:** Text Classification - Sentiment Analysis  \n",
    "**Team Members:**\n",
    "- [Team Member 1]\n",
    "- [Team Member 2]\n",
    "- [Team Member 3]\n",
    "- [Team Member 4]\n",
    "\n",
    "## Assignment Requirements\n",
    "- Compare traditional ML (Logistic Regression, SVM, Naive Bayes) vs Deep Learning (RNN, LSTM, GRU)\n",
    "- Use publicly available dataset (IMDB, Twitter sentiment, Amazon reviews)\n",
    "- Conduct EDA with statistical analysis and visualizations\n",
    "- Apply various text preprocessing and embedding techniques\n",
    "- Include 2+ experiment tables with parameter variations\n",
    "- Evaluate with appropriate metrics (MSE, cross-entropy, etc.)\n",
    "- Submit PDF report + GitHub repo\n",
    "\n",
    "## Team Contributions\n",
    "| Member | Tasks |\n",
    "|--------|-------|\n",
    "| [Name] | [Specific contributions] |\n",
    "| [Name] | [Specific contributions] |\n",
    "| [Name] | [Specific contributions] |\n",
    "| [Name] | [Specific contributions] |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Import necessary libraries\n",
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Text preprocessing\n",
    "# TODO: Add NLTK, sklearn text processing imports\n",
    "\n",
    "# Traditional ML models\n",
    "# TODO: Add sklearn models (LogisticRegression, SVM, MultinomialNB)\n",
    "\n",
    "# Deep Learning\n",
    "# TODO: Add TensorFlow/Keras imports for LSTM, GRU, etc.\n",
    "\n",
    "# Evaluation\n",
    "# TODO: Add metrics imports\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "# TODO: Set TensorFlow seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset Selection and Loading\n",
    "\n",
    "**Choose ONE dataset:**\n",
    "- IMDB Movie Reviews (50k reviews)\n",
    "- Twitter Sentiment Dataset\n",
    "- Amazon Product Reviews\n",
    "- Custom dataset\n",
    "\n",
    "**Justify your choice:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load your chosen dataset\n",
    "# Option 1: Load from Keras datasets\n",
    "# Option 2: Load from CSV file\n",
    "# Option 3: Download from online source\n",
    "\n",
    "# Example structure:\n",
    "# df = pd.read_csv('your_dataset.csv')\n",
    "# or\n",
    "# from tensorflow.keras.datasets import imdb\n",
    "\n",
    "print(\"Dataset loaded successfully!\")\n",
    "print(f\"Shape: {df.shape if 'df' in locals() else 'Load dataset first'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis (EDA)\n",
    "\n",
    "**Requirements:**\n",
    "- Statistical analysis of dataset\n",
    "- Visualizations to understand data distribution\n",
    "- Class balance analysis\n",
    "- Text length analysis\n",
    "- Word frequency analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Basic dataset information\n",
    "print(\"=== Dataset Overview ===\")\n",
    "# Shape, columns, data types, missing values\n",
    "\n",
    "# TODO: Display sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Sentiment distribution analysis\n",
    "print(\"=== Sentiment Distribution ===\")\n",
    "# Value counts, percentages\n",
    "\n",
    "# TODO: Create visualizations\n",
    "# Pie chart, bar chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Text length analysis\n",
    "print(\"=== Text Length Analysis ===\")\n",
    "# Character count, word count statistics\n",
    "\n",
    "# TODO: Create histograms and box plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Word frequency analysis\n",
    "print(\"=== Word Frequency Analysis ===\")\n",
    "# Most common words overall\n",
    "# Most common words by sentiment\n",
    "\n",
    "# TODO: Create word clouds (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Text Preprocessing\n",
    "\n",
    "**Requirements:**\n",
    "- Handle missing values\n",
    "- Tokenization\n",
    "- Stopword removal\n",
    "- Text cleaning (punctuation, numbers, etc.)\n",
    "- **Justify your preprocessing choices**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create text preprocessing function\n",
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Preprocess individual text\n",
    "    \n",
    "    Steps:\n",
    "    1. Lowercase\n",
    "    2. Remove punctuation\n",
    "    3. Remove numbers\n",
    "    4. Remove stopwords\n",
    "    5. Tokenization\n",
    "    6. Stemming/Lemmatization\n",
    "    \"\"\"\n",
    "    # TODO: Implement preprocessing steps\n",
    "    return processed_text\n",
    "\n",
    "# TODO: Apply preprocessing to dataset\n",
    "# df['cleaned_text'] = df['text'].apply(preprocess_text)\n",
    "\n",
    "# TODO: Show before/after examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Justification\n",
    "\n",
    "**TODO: Explain your preprocessing choices:**\n",
    "- Why did you choose specific steps?\n",
    "- How do they benefit your models?\n",
    "- Any trade-offs considered?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature Engineering and Embeddings\n",
    "\n",
    "**Requirements:**\n",
    "- Implement multiple embedding techniques\n",
    "- Compare TF-IDF, Word2Vec, GloVe, etc.\n",
    "- Justify choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Split data into train/test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X = df['cleaned_text']\n",
    "# y = df['sentiment']\n",
    "# X_train, X_test, y_train, y_test = train_test_split(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: TF-IDF Vectorization\n",
    "print(\"Creating TF-IDF features...\")\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# TODO: Implement and fit TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Bag of Words (Count Vectorization)\n",
    "print(\"Creating BoW features...\")\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# TODO: Implement Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Word2Vec Embeddings\n",
    "print(\"Creating Word2Vec embeddings...\")\n",
    "# from gensim.models import Word2Vec\n",
    "\n",
    "# TODO: Train Word2Vec model\n",
    "# TODO: Convert texts to embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Optional - GloVe embeddings\n",
    "# Load pre-trained GloVe vectors if available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Traditional Machine Learning Models\n",
    "\n",
    "**Requirements:**\n",
    "- Implement at least: Logistic Regression, SVM, Naive Bayes\n",
    "- Test with different feature sets\n",
    "- Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement Logistic Regression\n",
    "print(\"Training Logistic Regression...\")\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# TODO: Train and evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement SVM\n",
    "print(\"Training SVM...\")\n",
    "# from sklearn.svm import SVC\n",
    "\n",
    "# TODO: Train and evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement Naive Bayes\n",
    "print(\"Training Naive Bayes...\")\n",
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# TODO: Train and evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Store and compare results\n",
    "traditional_results = []\n",
    "# Store results in list of dictionaries for comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Deep Learning Models\n",
    "\n",
    "**Requirements:**\n",
    "- Implement at least: RNN, LSTM, GRU\n",
    "- Compare architectures\n",
    "- Hyperparameter experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Prepare data for deep learning\n",
    "print(\"Preparing sequences for deep learning...\")\n",
    "# from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "# from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# TODO: Tokenize and pad sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create LSTM model\n",
    "def create_lstm_model(vocab_size, embedding_dim=100, lstm_units=64):\n",
    "    # TODO: Implement LSTM architecture\n",
    "    # Use Sequential API\n",
    "    # Layers: Embedding, LSTM, Dense, Dropout\n",
    "    pass\n",
    "\n",
    "# TODO: Train LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create GRU model\n",
    "def create_gru_model(vocab_size, embedding_dim=100, gru_units=64):\n",
    "    # TODO: Implement GRU architecture\n",
    "    pass\n",
    "\n",
    "# TODO: Train GRU model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create Bidirectional LSTM\n",
    "def create_bidirectional_lstm(vocab_size, embedding_dim=100, lstm_units=64):\n",
    "    # TODO: Implement Bidirectional LSTM\n",
    "    pass\n",
    "\n",
    "# TODO: Train Bidirectional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Store deep learning results\n",
    "deep_learning_results = []\n",
    "# Store results for comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Experiment Tables (Required)\n",
    "\n",
    "**Create at least 2 experiment tables with parameter variations**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1: Traditional ML Hyperparameter Tuning\n",
    "\n",
    "| Model | Feature Type | Hyperparameters | Accuracy | Precision | Recall | F1-Score | MSE | Cross-Entropy |\n",
    "|-------|--------------|-----------------|----------|-----------|--------|----------|-----|---------------|\n",
    "| TODO  | TODO         | TODO            | TODO     | TODO      | TODO   | TODO     | TODO| TODO          |\n",
    "| TODO  | TODO         | TODO            | TODO     | TODO      | TODO   | TODO     | TODO| TODO          |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement hyperparameter tuning for traditional ML\n",
    "# Use GridSearchCV or manual parameter testing\n",
    "experiment1_results = []\n",
    "\n",
    "# Example parameters to test:\n",
    "# Logistic Regression: C values, solvers\n",
    "# SVM: C values, kernels\n",
    "# Different feature sets: TF-IDF vs BoW vs Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2: Deep Learning Architecture Variations\n",
    "\n",
    "| Model | Embedding Dim | Hidden Units | Dropout | Batch Size | Epochs | Accuracy | F1-Score | Cross-Entropy |\n",
    "|-------|---------------|--------------|---------|------------|--------|----------|----------|---------------|\n",
    "| TODO  | TODO          | TODO         | TODO    | TODO       | TODO   | TODO     | TODO     | TODO          |\n",
    "| TODO  | TODO          | TODO         | TODO    | TODO       | TODO   | TODO     | TODO     | TODO          |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement architecture variations for deep learning\n",
    "experiment2_results = []\n",
    "\n",
    "# Example parameters to test:\n",
    "# Embedding dimensions: 50, 100, 200\n",
    "# Hidden units: 32, 64, 128\n",
    "# Dropout rates: 0.3, 0.5, 0.7\n",
    "# Batch sizes: 16, 32, 64\n",
    "# Learning rates: 0.001, 0.01, 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Model Evaluation and Metrics\n",
    "\n",
    "**Requirements:**\n",
    "- Use appropriate performance metrics\n",
    "- Justify metric choices\n",
    "- Include MSE and cross-entropy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement comprehensive evaluation\n",
    "def evaluate_model(y_true, y_pred, y_pred_proba=None):\n",
    "    \"\"\"\n",
    "    Calculate comprehensive evaluation metrics\n",
    "    \"\"\"\n",
    "    # TODO: Calculate all required metrics\n",
    "    # Accuracy, Precision, Recall, F1-score\n",
    "    # MSE, Cross-entropy loss\n",
    "    pass\n",
    "\n",
    "# TODO: Apply to all models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric Justification\n",
    "\n",
    "**TODO: Explain why you chose each metric:**\n",
    "\n",
    "1. **Accuracy**: [Your justification]\n",
    "2. **Precision**: [Your justification]\n",
    "3. **Recall**: [Your justification]\n",
    "4. **F1-Score**: [Your justification]\n",
    "5. **MSE**: [Your justification]\n",
    "6. **Cross-Entropy**: [Your justification]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create confusion matrices\n",
    "# For best performing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create performance comparison visualizations\n",
    "# Bar charts, heatmaps, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Results Analysis and Discussion\n",
    "\n",
    "**Requirements:**\n",
    "- Compare traditional ML vs deep learning\n",
    "- Discuss key findings\n",
    "- Explain performance variations\n",
    "- Suggest potential improvements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Summarize all results\n",
    "print(\"=== Final Results Summary ===\")\n",
    "\n",
    "# TODO: Create comprehensive comparison table\n",
    "final_results = pd.DataFrame()\n",
    "\n",
    "# TODO: Identify best performing model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Findings\n",
    "\n",
    "**TODO: Discuss your findings:**\n",
    "\n",
    "1. **Best performing model**: [Model name and performance]\n",
    "2. **Traditional ML vs Deep Learning**: [Comparison and insights]\n",
    "3. **Feature representation impact**: [TF-IDF vs Word2Vec vs others]\n",
    "4. **Preprocessing impact**: [Effect of different preprocessing steps]\n",
    "5. **Hyperparameter sensitivity**: [Most important parameters]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Variations Explanation\n",
    "\n",
    "**TODO: Explain why certain models performed better:**\n",
    "\n",
    "- **Dataset characteristics**: [Size, complexity, domain]\n",
    "- **Model suitability**: [Why certain models work better]\n",
    "- **Feature engineering**: [Impact of different representations]\n",
    "- **Hyperparameter choices**: [Effect of parameter tuning]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Potential Improvements\n",
    "\n",
    "**TODO: Suggest improvements:**\n",
    "\n",
    "1. **Data improvements**: [More data, better preprocessing]\n",
    "2. **Model enhancements**: [Architecture modifications, ensembles]\n",
    "3. **Feature engineering**: [Advanced embeddings, feature selection]\n",
    "4. **Hyperparameter optimization**: [Advanced tuning methods]\n",
    "5. **Evaluation improvements**: [Additional metrics, cross-validation]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Conclusions\n",
    "\n",
    "**TODO: Write your conclusions:**\n",
    "\n",
    "1. **Main findings summary**\n",
    "2. **Best approach recommendation**\n",
    "3. **Lessons learned**\n",
    "4. **Future work suggestions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. References\n",
    "\n",
    "**TODO: Add your references:**\n",
    "\n",
    "1. Dataset source\n",
    "2. Literature references\n",
    "3. Code/library references\n",
    "4. Any other relevant sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Assignment Checklist\n",
    "\n",
    "**Before submission, ensure you have:**\n",
    "\n",
    "- [ ] Chosen and loaded appropriate dataset\n",
    "- [ ] Completed comprehensive EDA with visualizations\n",
    "- [ ] Implemented text preprocessing with justification\n",
    "- [ ] Applied multiple embedding techniques (TF-IDF, Word2Vec, etc.)\n",
    "- [ ] Implemented traditional ML models (LR, SVM, NB)\n",
    "- [ ] Implemented deep learning models (RNN, LSTM, GRU)\n",
    "- [ ] Created 2+ experiment tables with parameter variations\n",
    "- [ ] Used appropriate evaluation metrics (MSE, cross-entropy, etc.)\n",
    "- [ ] Justified metric choices\n",
    "- [ ] Compared results and discussed findings\n",
    "- [ ] Explained performance variations\n",
    "- [ ] Suggested potential improvements\n",
    "- [ ] Documented team member contributions\n",
    "- [ ] Prepared PDF report\n",
    "- [ ] Set up GitHub repository with README\n",
    "- [ ] Ensured code is well-documented and reproducible"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
